import csv
from random import shuffle

# Reading the names of the saved images from the csv file, generated by the training mode in the simulator

lines = []    # list of all rows, in the csv file
#Opening csv file:
with open('./data/driving_log.csv') as csvfile:
    reader = csv.reader(csvfile)
    for line in lines:
        samples.append(line)
        
#splitting training data into training and validation, so that hyperparameter tuning is possible
from sklearn.model_selection import train_test_split
train_samples, validation_samples = train_test_split(samples, test_size=0.2)

import cv2
import numpy as np
import sklearn

'''
A custom generator so that, this code can be reused even for a very large dataset, without 
running out of the memory
'''
def generator(samples, batch_size=32):
  num_samples = len(samples)
  while 1: # So that the generator never ends, and keeps on creating more and more images
    shuffle(samples)  # Shuffling the images, once again so that we don't get any bias
    for offset in range(0, num_samples, batch_size):
      batch_samples = samples[offset:offset+batch_size]

      images = []    # The list which contains the image arrays for the present bunch of generated images
      angles = []    # The list which contains the angle measurements for the present bunch of generated images
      for batch_sample in batch_samples:
        name = './data/IMG/'+batch_sample[0].split('/')[-1]
        center_image = cv2.imread(name)
        
        #converting image from BGR to RGB
        # This is because the drive.py actually sees in the RGB space, so it is natural to train in 
        # in the same space as well
        center_image = cv2.cvtColor(center_image,cv2.COLOR_BGR2RGB)
        center_angle = float(batch_sample[3])

        #Flipping the image
        # So that we don't have any bias towards a particular stearing angle
        flip=cv2.flip(center_image,1)
        images.append(center_image)
        angles.append(center_angle)
        images.append(flip)
        angles.append(center_angle*-1)

        left_image=cv2.imread('./data/IMG/'+batch_sample[1].split('/')[-1])
        left_image=cv2.cvtColor(left_image,cv2.COLOR_BGR2RGB)
        left_angle=center_angle+0.2
        right_image=cv2.imread('./data/IMG/'+batch_sample[2].split('/')[-1])
        right_image=cv2.cvtColor(right_image,cv2.COLOR_BGR2RGB)
        right_angle=center_angle-0.2
        images.append(left_image)
        images.append(right_image)
        angles.append(left_angle)
        angles.append(right_angle)

      X_train = np.array(images)     # Converting the images to numpy arrays
      y_train = np.array(angles)     # Converting the stearing angle measurements to numpy arrays
      yield sklearn.utils.shuffle(X_train, y_train)   # returning the shuffled numpy arrays

def createPreProcessingLayers():
    """
    Creates a model with the initial pre-processing layers.
    Normalize and mean center the images
    Crop the excess pixels from the top and the bottom
    """
    model = Sequential()
    model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))
    model.add(Cropping2D(cropping=((50,20), (0,0))))    
    return model

def nVidiaModel():
    """
    Creates nVidea Autonomous Car Group model
    This model is bases on the research paper by Nvidia for the self driving cars
    It baiscally consists of three convolution layers followed by three full connected layers
    """
    model = createPreProcessingLayers()
    model.add(Convolution2D(24,5,5, subsample=(2,2), activation='relu',W_regularizer=l2(0.001)))
    model.add(ELU())
    model.add(Convolution2D(36,5,5, subsample=(2,2), activation='relu',W_regularizer=l2(0.001)))
    model.add(ELU())
    model.add(Convolution2D(48,5,5, subsample=(2,2), activation='relu',W_regularizer=l2(0.001)))
    model.add(ELU())
    model.add(Convolution2D(64,3,3, activation='relu',W_regularizer=l2(0.001)))
    model.add(ELU())
    model.add(Convolution2D(64,3,3, activation='relu',W_regularizer=l2(0.001)))
    model.add(ELU())
    model.add(Flatten())
    model.add(Dense(100,W_regularizer=l2(0.001)))
    model.add(ELU())
    model.add(Dense(50,W_regularizer=l2(0.001)))
    model.add(ELU())
    model.add(Dense(10,W_regularizer=l2(0.001)))
    model.add(ELU())
    model.add(Dense(1))
    return model

# compile and train the model using the generator function
train_generator = generator(train_samples, batch_size=32)
validation_generator = generator(validation_samples, batch_size=32)


# Import all the necessary keras libraries for the purpose of training the model
from keras.models import Sequential
from keras.layers import Flatten,Dense,Activation,Dropout,Lambda,Cropping2D
from keras.layers.convolutional import Convolution2D
from keras.layers.advanced_activations import ELU
from keras.regularizers import l2, activity_l2
from keras import regularizers
model= nVidiaModel()   # The model is completely defined

# Compile the model
model.compile(loss='mse', optimizer='adam',metric='accuracy')

# Use the fit_generator() function to use the train_generator and validation_generator to fit on the data
model.fit_generator(train_generator, samples_per_epoch=len(train_samples)*4, validation_data=validation_generator,nb_val_samples=len(validation_samples), nb_epoch=10,verbose=1,show_accuracy=True)

#Saving the mddel.
model.save('model.h5')